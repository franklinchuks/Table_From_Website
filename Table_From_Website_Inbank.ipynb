{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_from_website(url):\n",
    "  response = requests.get(url)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    if table:\n",
    "      table_data = []\n",
    "      rows = table.find_all('tr')\n",
    "      for row in rows:\n",
    "        row_data = []\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        for cell in cells:\n",
    "          cell_text = cell.text.strip()\n",
    "          row_data.append(cell_text)\n",
    "        table_data.append(row_data)\n",
    "      return table_data\n",
    "    else:\n",
    "      print(\"No table found on the website.\")\n",
    "  else:\n",
    "    print(f\"Error getting website content: {response.status_code}\")\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '2019', '2020', '2021', '2022', '2023']\n",
      "['Net interest income', '31.7', '36', '40.0', '48.1', '53.4']\n",
      "['Net rental and other income', '0.3', '−1.1', '2.6', '3.3', '6.8']\n",
      "['Total net income', '32.0', '34.8', '42.6', '51.4', '60.2']\n",
      "['Operating expenses', '16.0', '17.3', '24.0', '30.3', '36.9']\n",
      "['Operating profit', '16.0', '17.5', '18.6', '21.0', '23.2']\n",
      "['Impairment losses on loans', '6.0', '11.5', '6.7', '11.2', '13.2']\n",
      "['Net profit', '10.0', '5.9', '11.0', '21.1', '10.2']\n",
      "['GMV', '284.6', '300.9', '523.1', '576.9', '687.7']\n",
      "['Total assets', '462.8', '490.0', '787.0', '1 020.5', '1 320.6']\n",
      "['Loan and rental portfolio', '324.2', '389.2', '640.5', '815.9', '1 030.2']\n",
      "['Deposit portfolio', '377.5', '391.3', '617.9', '828.9', '1 081.6']\n",
      "[\"Owner's equity\", '47.3', '61.2', '79.0', '101.9', '124.1']\n",
      "['Return on equity (ROE)', '23.9%', '10.8%', '15.6%', '23.3%', '9.0%']\n",
      "['Return on total assets', '2.6%', '1.2%', '1.7%', '2.3%', '0.9%']\n",
      "['Net interest margin', '8.5%', '8.0%', '6.6%', '5.9%', '5.1%']\n",
      "['Impairment losses to loan portfolio', '2.1%', '3.1%', '1.3%', '1.6%', '1.6%']\n",
      "['Cost/income ratio', '49.9%', '49.7%', '56.3%', '59.0%', '61.4%']\n",
      "['Equity to total assets', '10.2%', '12.5%', '10.0%', '10.0%', '9.4%']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://inbank.eu/investors\"\n",
    "table_data = get_table_from_website(url)\n",
    "\n",
    "if table_data:\n",
    "  for row in table_data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table_to_excel(table_data, filename):\n",
    "  if not table_data:\n",
    "    print(\"No table data to save.\")\n",
    "    return\n",
    "  \n",
    "  wb = openpyxl.Workbook()\n",
    "  ws = wb.active\n",
    "  ws.title = \"Extracted Table Data\"\n",
    "\n",
    "  for row_index, row_data in enumerate(table_data):\n",
    "    for col_index, cell_text in enumerate(row_data):\n",
    "      ws.cell(row=row_index+1, column=col_index+1).value = cell_text\n",
    "\n",
    "  wb.save(filename)\n",
    "  print(f\"Table data saved to Excel file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"inbank_financial_performance.xlsx\"\n",
    "\n",
    "# if table_data:\n",
    "#   save_table_to_excel(table_data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_from_website(url, table_id=None, table_class=None):\n",
    "\n",
    "  # Send an HTTP GET request to the website\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Check if request was successful\n",
    "  if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the desired table using ID or class name\n",
    "    if table_id:\n",
    "      table = soup.find('table', id=table_id)\n",
    "    elif table_class:\n",
    "      table = soup.find('table', class_=table_class)\n",
    "    else:\n",
    "      print(\"Please provide either table ID or class name for identification.\")\n",
    "      return None\n",
    "\n",
    "    # Check if a table was found\n",
    "    if table:\n",
    "      # Extract table data (rows and cells)\n",
    "      table_data = []\n",
    "      rows = table.find_all('tr')\n",
    "      for row in rows:\n",
    "        row_data = []\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        for cell in cells:\n",
    "          # Extract cell text and strip any leading/trailing whitespace\n",
    "          cell_text = cell.text.strip()\n",
    "          row_data.append(cell_text)\n",
    "        table_data.append(row_data)\n",
    "      return table_data\n",
    "    else:\n",
    "      print(\"Desired table not found on the website.\")\n",
    "  else:\n",
    "    print(f\"Error getting website content: {response.status_code}\")\n",
    "  return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '2019', '2020', '2021', '2022', '2023']\n",
      "['Net interest income', '31.7', '36', '40.0', '48.1', '53.4']\n",
      "['Net rental and other income', '0.3', '−1.1', '2.6', '3.3', '6.8']\n",
      "['Total net income', '32.0', '34.8', '42.6', '51.4', '60.2']\n",
      "['Operating expenses', '16.0', '17.3', '24.0', '30.3', '36.9']\n",
      "['Operating profit', '16.0', '17.5', '18.6', '21.0', '23.2']\n",
      "['Impairment losses on loans', '6.0', '11.5', '6.7', '11.2', '13.2']\n",
      "['Net profit', '10.0', '5.9', '11.0', '21.1', '10.2']\n",
      "['GMV', '284.6', '300.9', '523.1', '576.9', '687.7']\n",
      "['Total assets', '462.8', '490.0', '787.0', '1 020.5', '1 320.6']\n",
      "['Loan and rental portfolio', '324.2', '389.2', '640.5', '815.9', '1 030.2']\n",
      "['Deposit portfolio', '377.5', '391.3', '617.9', '828.9', '1 081.6']\n",
      "[\"Owner's equity\", '47.3', '61.2', '79.0', '101.9', '124.1']\n",
      "['Return on equity (ROE)', '23.9%', '10.8%', '15.6%', '23.3%', '9.0%']\n",
      "['Return on total assets', '2.6%', '1.2%', '1.7%', '2.3%', '0.9%']\n",
      "['Net interest margin', '8.5%', '8.0%', '6.6%', '5.9%', '5.1%']\n",
      "['Impairment losses to loan portfolio', '2.1%', '3.1%', '1.3%', '1.6%', '1.6%']\n",
      "['Cost/income ratio', '49.9%', '49.7%', '56.3%', '59.0%', '61.4%']\n",
      "['Equity to total assets', '10.2%', '12.5%', '10.0%', '10.0%', '9.4%']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://inbank.eu/investors\"\n",
    "table_class = \"w-full\"\n",
    "\n",
    "table_data = get_table_from_website(url, table_class=table_class)\n",
    "\n",
    "if table_data:\n",
    "  for row in table_data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'webdriver' from 'selenide' (/usr/local/lib/python3.11/site-packages/selenide/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenide\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver, open_url, click, wait_for\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_table_from_website\u001b[39m(url, button_selector, table_selector):\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;66;03m# Open the website using Selenide\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   open_url(url)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'webdriver' from 'selenide' (/usr/local/lib/python3.11/site-packages/selenide/__init__.py)"
     ]
    }
   ],
   "source": [
    "from selenide import webdriver, open_url, click, wait_for\n",
    "\n",
    "def get_table_from_website(url, button_selector, table_selector):\n",
    "  # Open the website using Selenide\n",
    "  open_url(url)\n",
    "\n",
    "  # Click the button using the provided selector\n",
    "  click(button_selector)\n",
    "\n",
    "  # Wait for the desired table to be visible (adjust timeout if needed)\n",
    "  wait_for(table_selector, timeout=10)\n",
    "\n",
    "  # Get the HTML content of the entire page\n",
    "  html_content = driver.page_source\n",
    "\n",
    "  # Parse the HTML content using BeautifulSoup\n",
    "  soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "  # Find the desired table using the provided selector\n",
    "  table = soup.select_one(table_selector)\n",
    "\n",
    "  # Check if a table was found\n",
    "  if table:\n",
    "    # Extract table data (rows and cells)\n",
    "    table_data = []\n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "      row_data = []\n",
    "      cells = row.find_all(['td', 'th'])\n",
    "      for cell in cells:\n",
    "        # Extract cell text and strip any leading/trailing whitespace\n",
    "        cell_text = cell.text.strip()\n",
    "        row_data.append(cell_text)\n",
    "      table_data.append(row_data)\n",
    "    return table_data\n",
    "  else:\n",
    "    print(\"Desired table not found on the website.\")\n",
    "  return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_selector = \"#headlessui-tabs-tab-623477\"\n",
    "table_selector = \"w-full\"\n",
    "\n",
    "# Extract data from the table appearing after clicking the button\n",
    "table_data = get_table_from_website(url, button_selector, table_selector)\n",
    "\n",
    "if table_data:\n",
    "  # Print the extracted table data\n",
    "  for row in table_data:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
